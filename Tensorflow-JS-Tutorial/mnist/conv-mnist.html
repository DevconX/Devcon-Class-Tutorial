<html>
<div id="text">
</div>
<script src="../js/tf.js"></script>
<script src="../js/jquery-3.3.1.min.js"></script>
<script src="../js/utils.js"></script>
<script src="../data/mnist.js"> </script>
<script>
$('#text').append("Done load MNIST dataset, total row "+MNIST['data'].length+"<br>");
setTimeout(function(){
  const conv_layer1 = tf.layers.conv2d({filters: 3, kernelSize: [3, 3], strides: [1,1], padding:'same', activation: 'relu'});
  const conv_layer2 = tf.layers.conv2d({filters: 9, kernelSize: [3, 3], strides: [1,1], padding:'same', activation: 'relu'});
  const conv_layer3 = tf.layers.conv2d({filters: 16, kernelSize: [3, 3], strides: [1,1], padding:'same', activation: 'relu'});
  const max_pooling1 = tf.layers.maxPooling2d({poolSize: 2, strides: 2, padding:'same'});
  const max_pooling2 = tf.layers.maxPooling2d({poolSize: 2, strides: 2, padding:'same'});
  const max_pooling3 = tf.layers.maxPooling2d({poolSize: 2, strides: 2, padding:'same'});
  const dense_layer1 = tf.layers.dense({units: 100, activation: 'relu'});
  const dense_layer2 = tf.layers.dense({units: 10, activation: 'linear'});
  function f(x){
    forward = max_pooling1.apply(conv_layer1.apply(x));
    forward = max_pooling2.apply(conv_layer2.apply(forward));
    forward = max_pooling3.apply(conv_layer3.apply(forward));
    forward = forward.reshape([-1,4*4*16]);
    forward = dense_layer1.apply(forward);
    return dense_layer2.apply(forward);
  }
  const cost = (label, pred) => tf.losses.softmaxCrossEntropy(label, pred).mean();
  const accuracy = (label, pred) => tf.cast(tf.equal(label.argMax(1),pred.argMax(1)),'float32').mean();
  const learning_rate = 0.0001;
  const optimizer = tf.train.adam(learning_rate);
  const batch_size = 128;
  const epoch = 10;

  function async_training_loop(callback) {
    (function loop(i) {
      var total_loss = 0, total_acc = 0;
      for(var k = 0; k < Math.floor(MNIST['data'].length/batch_size)*batch_size; k+=batch_size){
        batch_x = tf.tensor(MNIST['data'].slice(k,k+batch_size)).reshape([-1,28,28,1]);
        batch_y = tf.tensor(MNIST['label'].slice(k,k+batch_size));
        total_loss += parseFloat(cost(batch_y, f(batch_x)).toString().slice(7));
        total_acc += parseFloat(accuracy(batch_y, f(batch_x)).toString().slice(7));
        optimizer.minimize(() => cost(batch_y, f(batch_x)));
      }
      total_loss /= Math.floor(MNIST['data'].length/batch_size);
      total_acc /= Math.floor(MNIST['data'].length/batch_size);
      $('#text').append('Epoch: '+(i+1)+', avg loss: '+total_loss+', avg acc: '+total_acc+'<br>');
      if (i < (epoch-1)) {
        setTimeout(function() {loop(++i)}, 1);
      } else {
        callback();
      }
    }(0));
  }
  async_training_loop(function() {
    $('#text').append('Done training!');
  });
}, 5);

</script>
</html>
